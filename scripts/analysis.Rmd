---
title: "Analysis"
author: "Quynh Tran"
date: "April 10, 2015"
output: html_document
---


```{r read_data, echo=FALSE}
library(randomForest)
library(miscTools)
library(reshape2)
library(caret)
library(ggplot2)
library(dplyr)

cohort8_clams <- read.csv(file="../data/processed/clams_training_data.csv", header=TRUE)
cohort9_clams <- read.csv(file="../data/processed/clams_testing_data.csv", header=TRUE)

cohort8_weight <- read.csv( file="../data/processed/body_compostition_training_data.csv", header=T)
cohort9_weight <- read.csv( file="../data/processed/body_compostition_testing_data.csv", header=T)

cohort8_clams_weight <- read.csv(file="../data/processed/Combined_BC_clams_training_data.csv", header=T)

cols <- c("Subject", "RER", "SumXYAmb", "VO2.LBM", "Fast", "Light.Dark")
cohort8_clams_LBM <- cohort8_clams_weight[, cols]
cohort8_clams_LBM$Fast <- ifelse(cohort8_clams_LBM$Fast=="Bf_fasting",  "Pre_fasting", 
                                 ifelse(cohort8_clams_LBM$Fast=="After_fasting", "After_fasting", "During_fasting"))
cohort8_clams_LBM$Fast <- as.factor(cohort8_clams_LBM$Fast)

cohort8_mod <- merge(cohort8_weight, cohort8_clams_LBM, by.x=c("Subject", "Fasting_stat"), by.y=c("Subject", "Fast"), all=T)

cohort8_mod <- relevel(as.factor(cohort8_mod$Fasting_stat), ref='Pre_fasting')

cohort8_m_data<-
  cohort8_mod %>%
  group_by(Subject, Light.Dark, Fasting_stat) %>%
  summarise(
    RER = mean(RER),
    SumXYAmb = mean(SumXYAmb),
    VO2.LBM = mean(VO2.LBM),
    Lean=mean(Lean),
    Fat=mean(Fat),
    Percent.Fat=mean(Percent.Fat),
    Weight=mean(Weight))
cohort8_m_data<-as.data.frame(cohort8_m_data)

cohort8_m_data <- cohort8_m_data[!cohort8_m_data$Fasting_stat=="During_fasting",]
cohort8_m_data[is.na(cohort8_m_data$Light.Dark), 2] <- "Light"

model_data <- read.csv(file='../data/processed/cohort8_longitudinal_data_for_modelling.csv', header=T)
cohort9_model_data <- read.csv(file='../data/processed/cohort9_longitudinal_data_for_modelling.csv', header=T)

cohort8_weight <- read.csv( file="../data/processed/body_compostition_training_data.csv", header=T)
#sub_cohort8_weight <- as.data.frame(cohort8_weight[, c(3, 7:11)])
#cohort8_weight_wide <- reshape(sub_cohort8_weight, idvar="Subject", timevar="Fasting_stat", v.names=c("Lean", "Fat", "Weight","Percent.Fat"), direction="wide")
#combine data from cohort8 and 9
combine.data <- rbind(model_data, cohort9_model_data)

#LINEAR MIXED EFFECT MODEL
library(lme4)

cohort8_model_light <- subset(cohort8_m_data, Light.Dark=="Light")

weight.lme <- lmer(Weight~ Lean+ Percent.Fat+ Fasting_stat +
                     RER + SumXYAmb + VO2.LBM + (1|Subject), 
                   data=cohort8_model_light)

rescale_data <- cohort8_model_light
rescale_data[,c(4:9)] <- scale(rescale_data[, c(4:9)])
weight.lme_scale <- update(weight.lme, data=rescale_data)

plot(predict(weight.lme), residuals(weight.lme))
# standardized residuals versus fitted values by gender
plot(weight.lme, resid(.) ~ fitted(.), abline = 0)

#box-plots of residuals by Subject
plot(weight.lme, Subject~resid(.))

#observed versus fitted values by Subject
plot(weight.lme, Weight ~ predict(.), abline = c(0,1))

plot(density(resid(weight.lme)))

qqnorm(weight.lme, ~ranef(., level=1))

library(REEMtree)
sub_model_data <- model_data[!model_data$Fast=="After_fasting",]
model_data_wide <- reshape(cohort8_model_light, timevar="Light.Dark", idvar="Subject", direction="wide", v.names=c( "RER", "VO2.LBM", "SumXYAmb"))
#Fit a RE-EM tree to data. This estimates a regression tree combined with a linear random effects model.
weight.rf <- REEMtree(Weight~ Lean + Percent.Fat +Fasting_stat+
                      VO2.LBM + RER + SumXYAmb 
                    , data=rescale_data, random=~1|Subject)
#print a description of a fitted REEM tree object
print(weight.rf)
fitted(weight.rf)
#plot the 
plot.REEMtree(weight.rf, text=T)
#extrct the estimated random effects from the fitted REEM tree
ranef(weight.rf)

plot(density(residuals(weight.rf)))
tree(weight.rf)

cohort9_model_data$Subject <- as.factor(cohort9_model_data$Subject)
#sub_cohort9_model_data <- cohort9_model_data[!cohort9_model_data$Avg.Percent.LL <= 0,]

combine.data <- rbind(sub_model_data[ ,c(1:8, 10)], sub_cohort9_model_data[, 2:7])

#estimate using the cohort8 only so make the 144 observation TRUE for cohort 8
# with predictions for all observations
sub_combine.data<-subset(combine.data, Light.Dark=="Light")
sub <- c(rep(TRUE, 100), rep(FALSE, 62))
weight.rf2 <- REEMtree(Weight~ VO2.LBM + RER + SumXYAmb+
                     Fasting_stat
                    , data=sub_combine.data, random=~1|Subject, subset=sub)

#weight.rf2 <- REEMtree(Percent.WG~ VO2.LBM + RER + SumXYAmb+
 #                    Avg.Percent.FL + Avg.Percent.LL + Light.Dark + Fast
  #                  , data=combine.data, random=~1|Subject, subset=sub)

predict1 <- predict(weight.rf2, sub_combine.data ,  EstimateRandomEffects=F)
#calculate r2 and mse
r2_1 <- rSquared(sub_combine.data$Weight, sub_combine.data$Weight - predict1)
mse_1 <- mean((sub_combine.data$Weight - (predict1))^2)

predict2 <- predict(weight.rf2, sub_combine.data , id=sub_combine.data$Subject, EstimateRandomEffects=TRUE)

r2_2 <- rSquared(sub_combine.data$Weight, sub_combine.data$Weight - predict2)
mse_2 <- mean((sub_combine.data$Weight - (predict2))^2)

#print a description of a fitted REEM tree object
print(weight.rf2)
fitted(weight.rf2)
#plot the 
plot.REEMtree(weight.rf2, text=T)
#extrct the estimated random effects from the fitted REEM tree
ranef(weight.rf2)

plot(density(residuals(weight.rf2)))
tree(weight.rf2)

plot(weight.rf2, resid(.) ~ fitted(.), abline = 0)

```


````{r random forest, echo=FALSE}
tst <- rfcv(model_data_wide[, predictors_light], model_data_wide$Percent.WG, scale="log", step=0.5, cv.fold=2, recursive=T)
pairs(tst$n.var, tst$error.cv)


#Find the optimal number of variables to try splitting at each node
bestmtry <- tuneRF(model_data_wide[, predictors_light], model_data_wide$Percent.WG,  ntreeTry=100, 
     stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE, dobest=FALSE)

#making the tuning grid
#grid_rf <- expand.grid(.mtry=c(2,4, 8))
#m_rf <- train(Percent.WG~., data=training[,predictors], method="rf", metric="Rsquared", tuneGrid=grid_rf)

#The optimal number of variables for splitting is 4
rf <- randomForest(Percent.WG~., data=model_data_wide[,predictors_light], ntree=1000, mtry=3, importance=TRUE,keep.forest=TRUE, proximity=TRUE)


varImpPlot(rf)
varUsed(rf)
wg.prox<- rf$proximity
wg.mds <- cmdscale(1-wg.prox)
plot(wg.mds, col = c("blue","orange"), pch = c(1,16), xlab="", ylab="")

par(mfrow=c(1,1))
library(calibrate)
plot(rf)
import <- as.data.frame(importance(rf))
colnames(import) <- c("PercentIncMSE", "IncNodePurity")
plot(import$PercentIncMSE, import$IncNodePurity)
textxy(import$PercentIncMSE, import$IncNodePurity, labs=rownames(import), m=c(0,0), cex=0.5, offset=0.6)
ggplot(import, aes(x=PercentIncMSE,y=IncNodePurity)) + 
    geom_point() + 
    geom_text(aes(label=rownames(import)))
```

```{r k-fold cross validation, echo=FALSE}
k = 10 #Folds
 
# sample from 1 to k, nrow times (the number of observations in the data)
merge_LD$id <- sample(1:k, nrow(merge_LD), replace = TRUE)
list <- 1:k
 
# prediction and testset data frames that we add to with each iteration over
# the folds
 
prediction <- data.frame()
testsetCopy <- data.frame()
 
#Creating a progress bar to know the status of CV
progress.bar <- create_progress_bar("text")
progress.bar$init(k)

for (i in 1:k){
  # remove rows with id i from dataframe to create training set
  # select rows with id i to create test set
  trainingset <- subset(merge_LD, id %in% list[-i])
  testset <- subset(merge_LD, id %in% c(i))
  
  # run a random forest model
  mymodel <- randomForest(trainingset$Percent.WG ~ ., data = trainingset, ntree = 600, mtry=4)
                                                     
  # remove response column 1, Percent.WG
  temp <- as.data.frame(predict(mymodel, testset[,-7]))
  # append this iteration's predictions to the end of the prediction data frame
  prediction <- rbind(prediction, temp)
  
  #calculate r2 and mse
  r2 <- rSquared(testset$Percent.WG, testset$Percent.WG - predict(mymodel, testset[,predictors]))
  
  mse <- mean((testset$Percent.WG - predict(mymodel, testset[,predictors]))^2)
  
  # append this iteration's test set to the test set copy data frame
  # keep only the Percent.WG Column
  testsetCopy <- rbind(testsetCopy, as.data.frame(testset[,7]), mse)
  
  progress.bar$step()
}
 
# add predictions and actual Percent.WG values
result <- cbind(prediction, testsetCopy[,1])
names(result) <- c("Predicted", "Actual")
result$Difference <- abs(result$Actual - result$Predicted)
result$r2 <- rSquared(result$Actual, results$Actual - result$Predicted)
#result$
plot(result)
# As an example use Mean Absolute Error as Evalution 
summary(result$Difference)
 
 
```

```{r Test data set, echo=FALSE}
#partition the data
idx <- createDataPartition(y=merge_LD$Percent.WG, p=0.75, list=FALSE )
training <- merge_LD[idx,]
testing <- merge_LD[-idx,]
set.seed(300)
par(mfrow=c(1,1))
#look at the importance of the predictors, higer value means more importance
round(importance(rf),2)
predictors1 <- c('Subject', 'Avg.Percent.LL', 'Avg.Percent.FL',
      
                 'VO2.LBM.Bf_fasting.x','VO2.LBM.After_fasting.x',
              'VO2.LBM.Bf_fasting.y', 'VO2.LBM.After_fasting.y',
                 'RER.Bf_fasting.x', 'REF.AFter_fasting.x',
                'SumXYAmb.After_fasting.y','SumXYAmb.Bf_fasting.y', 
              'Percent.WG')

rf <- randomForest(Percent.WG~., data=training[,predictors1], ntree=600, mtry=4, test=testing$Precent.WG, importance=TRUE,
                   keep.forest=TRUE, proximity=TRUE)

r2 <- rSquared(testing$Percent.WG, testing$Percent.WG - predict(rf, testing[,predictors1]))

mse <- mean((testing$Percent.WG - predict(rf, testing[,predictors1]))^2)

p <- ggplot(aes(x=actual, y=pred),
  data=data.frame(actual=testing$Percent.WG, pred=predict(rf, testing[,predictors1])))
p + geom_point() +
  geom_abline(color="red") +
  ggtitle(paste("RandomForest Regression in R r^2=", r2, sep=""))
```

We used random forest to predict the mice weights after HFD. The predictors are Subject, Prefasting weight, After_fasting weight, VO2, RER, Light.Dark, Sum of X and Y ambulatories, and the Fasting status. 

```

You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
